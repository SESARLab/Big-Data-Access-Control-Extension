\section{Coalition Building}\label{sec:coalition}
Coalition building is a crucial process having direct impact on the quality of the analytics results. Figure~\ref{fig:smet} shows how data lineage is impacted by the processing lineage and in particular by i) the \textit{coalition a\-greement} $\textit{CA}_C$ (i.e., the CA-driven transformations adopted for a give coalition) and by ii) the transformation produced by the different jobs (job-specific transformation) part of a given coalition \coalition{}.
Let us consider job $\job{1}^{\org{1}}$ of Figure~\ref{fig:smet} it receives as input the data \trans{1}(\dataset{1}) based on the dataset obtained by \dataset{1} after the transformation  \trans{1} which is associated to the data lineage by our AC model. It then produce a data that is the job-specific transformation on the input data (i.e., \trans{1}(\dataset{1})) generating \dataset{2}.
We note that our Big Data Analytics pipeline models includes alternatives allowing different processing lineage (linear independent path in the Big data graph G) doing the same analytics but using different jobs (e.g., a lineage including k-means or a lineage using c-means). This will lead to different job-specific transformation on the data for the same Big Data pipeline.
In this paper, for the sake of simplicity we i) consider different coalitions for each processing lineage, ii) coalitions made of trustworthy organizations \org{i} providing candidate services for each job and iii) job-specific transformation not influenced by the organizations' behavior.
In this scenario, since any coalition of a given processing lineage will produce the same job-specific data transformation, the analytics pipeline quality is impacted only by the \textit{coalition agreement} $\textit{CA}_C$ or rather by the transformations \trans{i} imposed by the given coalition \coalition{} on the data lineage.
In the following we first present metrics to evaluate data quality across the data lineage, and then a set of solutions to build coalitions for  given Big Data pipeline ensuring a given data quality.

%\begin{example}\label{ex:p1j}
%The choice of the specific deployment has an impact on the way in which the coalition \coalition{} of organizations \org{i} is formed as discussed in the following of this section.
%Let us consider the following example where we have a pipeline made of just one ingestion job that can be offered by service provider $s_1$ or by the service provider $s_2$. In case the $s_1$ is selected the transformation $T_1$ is triggered according to the authorization $s_1$ has on the data, in this example $s_1$ has full control meaning that transformation $t_1$ is empty. In case the $s_2$ is selected the transformation $T_2$ is triggered according to the authorization $s_2$ has on the data and in this example data labelled as PII are removed.
%\end{example}
%Considering the two data lineage generated by the two different coalition in Example\ref{ex:p1j} the one involving $s_2$ produce a significant changes to data compared to the other one. This data changes can have direct impact on the quality of the analytics outcomes, therefore our goal is to build coalitions ensuring specific data quality. This coalition building problem can be assimilated to xxx showing an exponential complexity ...
%In the following we fist introduce our data quality metrics and then our euristics to solve the problem of coalition building

%\subsection{Data Quality metrics}
%\subsection{Coalition Heuristics}
\subsection{Metrics}

Data quality is a largely studied topic for the database management research communities,
and is in general focused on the quality of the data source rather then on the quality of the data outcomes or of the data while used in the processing pipeline.
In \cite{BigDataQaulitySurvey} a survey on big data quality is proposed mentioning the well known categories of big data quality grouped by intrinsic,
contextual representational and accessibility categories.

It also presents an holistic quality management model where the importance of data quality during processing is just mentioned in terms of requirements for the pre-processing job (e.g., data enhancement due to cleaning jobs).
In this paper we depart from this idea on data quality at pre processing time only measuring it at each step of the big data pipeline.
%data quality are divided into four categories: intrinsic, contextual representational and accessibility that covers almost all the aspects of data at ingestion time


In the following we present a set of metrics to evaluate the quality of the data at each step of the big data pipeline.
We

The proposed metrics can be classified into two categories, namely quantitative and statistical.
Initially, these metrics are applied to the original dataset (X) without any transformations, and subsequently, they are applied to the transformed dataset (Y).
The quantitative approach facilitates the calculation of the amount of data that has been lost during the transformation by enumerating the differences between X and Y.
On the other hand, the statistical approach takes into consideration the changes in certain statistical properties before and after the transformation.
These metrics can be applied either to the entire dataset or specific features.
The features can be assigned either equal or varying weights, which enables the prioritization of important features that were lost during the transformation.

% \item Metrica quantitativa
% \item Mean Squared Error (MSE). Let us considera two dataset X and Y of the same size. The MSE is defined as: $MSE(X,Y) = \frac{1}{n}\sum_{i=1}^{n}(x_i - y_i)^2$.
% \item Metrica quantitativa pesata
% \item Parametri statistici (deviazione standard, media, ecc)

\subsubsection{Jaqard coefficent}
Let us consider two dataset X and Y of the same size.
The Jaqard coefficent is defined as: $J(X,Y) = \frac{|X \cap Y|}{|X \cup Y|}$.
The use of Jaccard coefficient has several advantages when applied to datasets.
Unlike other similarity measures, such as Euclidean distance, Jaccard coefficient is not affected by the magnitude of the values in the dataset.
This property makes it suitable for datasets with categorical variables or nominal data, where the values do not have a meaningful numerical interpretation.
The coefficient ranges from 0 to 1, where 0 indicates no similarity and 1 indicates complete similarity between the sets.
\subsubsection{Jaqard coefficent with weights} Let us consider two dataset X and Y of the same size. The Jaqard coefficent is defined as: $J(X,Y) = \frac{\sum_{i=1}^{n}w_i(x_i \cap y_i)}{\sum_{i=1}^{n}w_i(x_i \cup y_i)}$.
Weighted Jaccard similarity is a variant of the Jaccard coefficient that incorporates weights to the elements in the sets being compared.
It allows for the prioritization of certain features or elements in the datasets.
This approach can be particularly useful when some elements in the dataset have more importance or relevance than others.
By assigning weights to the elements, the weighted Jaccard similarity can account for this importance and provide a more accurate measure of similarity.
\subsubsection{KL divergence} Let us consider two dataset X and Y of the same size. The KL divergence is defined as: $KL(X,Y) = \sum_{i=1}^{n}x_i \log \frac{x_i}{y_i}$.
\subsubsection{KL divergence with weights} Let us consider two dataset X and Y of the same size. The KL divergence is defined as: $KL(X,Y) = \sum_{i=1}^{n}w_i(x_i \log \frac{x_i}{y_i})$.


\subsubsection{pensieri di Ernesto}
\begin{itemize}
    \item In sede di ingestion, la valutazione sull'impatto dell'analitica la posso fare. Se privacy e valori numerici si può compiare epsilon e delta di differential privacy (noise addition o allargare la distribuzione di rumore sulla base del budget di privacy).
    \item Metriche quantitative, come ricercar potrebbe essere interessante schema di budget di privacy per l'offuscamento di dati non numerici Quante volte il dato viene trasformato
    \item Analitiche di statistica descrittiva per il 3sigma -> piattaforma di puliafito (Catania)
    \item Anomaly detection con deviazione standard
    \item Data sanitizzato fa il merge di due barre dell' istogramma è un' autoencoding, come cambia la deviazione standard
\end{itemize}
