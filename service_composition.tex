\section{Pipeline Template}
Our approach integrates data protection and data management into the service pipeline using annotations.
To this aim, we extend the service pipeline in \cref{def:pipeline} with: \emph{i)} data protection annotations expressing transformations on data to enforce data protection requirements, \emph{ii)} functional annotations expressing data manipulations carried out during services execution.
These annotations permit to implement an advanced data lineage, tracking the entire data lifecycle by monitoring changes arising from functional service execution and data protection requirements.

In the following, we first introduce the annotated service pipeline, called pipeline template in Section \ref{sec:templatedefinition}. We then present functional annotations (Section \ref{sec:funcannotation}) and data protection annotations (Section \ref{sec:nonfuncannotation}). We finally provide an example of a pipeline template (Section \ref{sec:example}).


\subsection{Pipeline Template Definition}\label{sec:templatedefinition}
Given the service pipeline in Definition~\ref{def:service_flow}, we use annotations to express data protection requirements to be enforced on data and functional requirements on services to be integrated in the pipeline. Each service node in the service pipeline is labeled with two mapping functions forming a pipeline template:
\begin{enumerate*}[label=\roman*)]
  \item a labeling function \myLambda:\V$\rightarrow$\P{} that associates a set of data protection requirements, in the form of policies $p_i\in$\P{}, with each node \vi{i}$\in$\V$_S$;
  \item a labeling function \myGamma:\V$\rightarrow$\F{} that associates a functional service description $F_i\in\F{}$ with each node \vi{i}$\in$\V$_S$.
\end{enumerate*}
%The policies will be intended to guide the enforcement of data protection while the data transformation function will characterize the functional aspect of each node.

The template is formally defined as follows.

\begin{definition}[Pipeline Template] \label{def:template}
  Given a service pipeline G(\V,\E), a pipeline template $G^{\myLambda,\myGamma}$(V,E,\myLambda,\myGamma) is a direct acyclic graph with two labeling functions:
  \begin{enumerate}[label=\roman*)]
    \item \myLambda that assigns a label \myLambda(\vi{i}), corresponding to a policy $p_i$ to be satisfied by service $s_i$ represented by \vi{i}, for each vertex $\vi{i}\in\V$;
    \item \myGamma that assigns a label \myGamma(\vi{i}), corresponding to the functional description $F_i$ of service $s_i$ represented by \vi{i}, for each vertex $\vi{i}\in\V$.
  \end{enumerate}
\end{definition}

We note that, at this stage, the template is not yet linked to any services, nor it is possible to determine the policy modeling the specific data protection requirements.
%We also note that functional description $F_i$ includes the specific data transformation triggered as the result of a service execution.
An example of pipeline template is depicted in \cref{fig:service_composition_template}

%The next sections better explain the functional and non-functional transformation functions.
\begin{figure}[ht!]
  \centering
  \begin{tikzpicture}[scale=0.9]
    % Nodes
    \node[draw, circle] (node1) at (0,0) {$\s{r}$};
    \node[draw, circle] (node2) at (1,0) {$\s{1}$};
    \node[draw, circle] (node3) at (2,0) {$\timesOperator$};
    \node[draw, circle] (node4) at (3,-1) {$\s{2}$};
    \node[draw, circle] (node5) at (3,1) {$\s{3}$};
    \node[draw, circle] (node6) at (4,0) {$\timesOperator$};
    \node[draw, circle] (node65) at (5,0) {$\s{4}$};
    \node[draw, circle] (node7) at (6,0) {$\plusOperator$};
    \node[draw, circle] (node8) at (7,1) {$\s{5}$};
    \node[draw, circle] (node9) at (7,-1) {$\s{6}$};
    \node[draw, circle] (node10) at (8,0) {$\plusOperator$};
    \node[draw, circle] (node11) at (9,0) {$\s{7}$};
    % Text on top
    \node[above] at (node1.north)  {$\templateChartAnnotation$};
    \node[above] at (node2.north)  {$\templateChartAnnotation$};
    \node[above] at (node3.north)  {                 };
    \node[above] at (node4.north)  {$\templateChartAnnotation$};
    \node[above] at (node5.north)  {$\templateChartAnnotation$};
    \node[above] at (node65.north) {$\templateChartAnnotation$};
    \node[above] at (node8.north)  {$\templateChartAnnotation$};
    \node[above] at (node9.north)  {$\templateChartAnnotation$};
    \node[above] at (node11.north) {$\templateChartAnnotation$};
    % Connection
    \draw[->] (node1) -- (node2);
    \draw[->] (node2) -- (node3);
    \draw[->] (node3) -- (node4);
    \draw[->] (node3) -- (node5);
    \draw[->] (node5) -- (node6);
    \draw[->] (node4) -- (node6);
    \draw[->] (node6) -- (node65);
    \draw[->] (node65) -- (node7);
    \draw[->] (node7) -- (node8);
    \draw[->] (node7) -- (node9);
    \draw[->] (node8) -- (node10);
    \draw[->] (node9) -- (node10);
    \draw[->] (node10) -- (node11);
  \end{tikzpicture}
  \caption{Pipeline Template}
  \label{fig:service_composition_template}
\end{figure}

\begin{figure}[ht!]
  \centering
  \begin{tikzpicture}
    % Nodes
    \node[draw, circle,minimum size=1cm] (node1) at (0,0) {$\s{1}$};
    \node[draw, circle,minimum size=1cm] (node2) at (2,0) {$\s{2}$};
    \node[draw, circle,minimum size=1cm] (node3) at (4,0) {$\s{3}$};

    \node[above] at (node1.north)  {$\templateChartAnnotation$};
    \node[above] at (node2.north)  {$\templateChartAnnotation$};
    \node[above] at (node3.north)  {$\templateChartAnnotation$};

    % Connection
    \draw[->] (node1) -- (node2);
    \draw[->] (node2) -- (node3);

  \end{tikzpicture}
  \caption{Pipeline Template Example}
  \label{fig:temp}
\end{figure}

\subsection{Functional Description}\label{sec:funcannotation}
A proper data management approach must track functional data manipulations across the entire pipeline execution,
defining the functional requirements of each service operating on data.
To this aim, each node \vi{i}$\in$\V$_S$ is annotated with a label \myGamma(\vi{i}), corresponding to the functional description $F_i$ of the service $s_i$ represented by \vi{i}.
$F_i$ describes the functional requirements on the corresponding service $s_i$, such as API, inputs, expected outputs.
%The latter is modeled as a functional transformation function \TF\ that is applied to the data when executing service $s_i$. \TF\ has a twofold role:
%\begin{enumerate}[label=\roman*)]
%  \item it contains the functional requirements that the service must satisfy, in terms of expected input, expected output, prototype and other functional aspects.
%  \item
It also specifies the specific data transformation function \TF{F}, triggered as the result of a service execution. %applied to the data when executing service $s_i$.

This function can be classified according to four types.
\begin{enumerate*}[label=\roman*)]
  \item Function \TF{\epsilon}, an empty function that applies no transformation or processing on the data.
  \item Function \TF{a}, an additive function that expands the amount of data received, for example, by integrating data from other sources.
  \item Function \TF{t}, a transformation function that transforms some records in the dataset without altering the domain.
  \item Function \TF{d} (out of the scope of this work), a transformation function that changes the domain of the data by applying, for instance, PCA or K-means.
\end{enumerate*}
%A transformation function can be classified according to four types.
% \begin{enumerate*}[label=\roman*)]
%   \item Function \F{e}, an empty function that applies no transformation or processing on the data.
%   \item Function \F{a}, an additive function that expands the amount of data received, for example, by integrating data from other sources.
%   \item Function \F{t}, a transformation function that transforms some records in the dataset without altering the domain.
%   \item Function \F{d}, a transformation function that changes the domain of the data by applying, for instance, PCA or K-means (out of the scope of this work).
% \end{enumerate*}

\subsection{Policy}\ref{sec:nonfuncannotation}
Policies express data protection requirements, specifying access permissions based on the context and actions taken by a service $s_i$ on data.
When a service applies for a node \vi{i}$\in$\V$_S$, his profile is compared against the associated node policy \myLambda(\vi{i}).
If the profile fails to meet the policy requirements, the service is discarded, otherwise it is deemed an appropriate match for the node.
Suitable services are then ranked based on their ability to retain the maximum amount of information.
When the chosen service requests access to a resource, the access control system filters the returned data according to the specified policies and based on the service profile.

Policy enforcement departs from traditional yes/no decision and always returns a positive evaluation subject to a data transformation.
Data transformation reduces the level of data access granted to the service and includes the possibility of returning an empty set, thus modeling a denied access.
In other words, we ensure data protection by removing or obfuscating sensitive attributes, instead of granting or denying access to the full data set.

We consider an attribute-based access control model that offers flexible fine-grained authorization and adapt its standard key components to address the unique characteristics of a big data environment.
An access control policy outlines access requirements in the form of policy conditions that are defined as follows.

\begin{definition}[Policy Condition]\label{def:policy_cond}
  A \emph{Policy Condition} is a Boolean expression of the form $($\emph{attr\_name} op \emph{attr\_value}$)$, with op$\in$\{$<$,$>$,$=$,$\neq$,$\leq$,$\geq$\}, \emph{attr\_name} an attribute label, and \emph{attr\_value} the corresponding attribute value.
\end{definition}

A policy is in turn defined as follows.

\begin{definition}[Policy]\label{def:policy_rule}
  A {\it policy P} is 5-uple $<$\textit{subj}, \textit{obj}, \textit{action}, \textit{env}, \textit{\TP}$>$, where:
  \begin{description}
    \item Subject \textit{subj} defines a user or the service provider of a job issuing access requests to perform operations on objects. It is of the form $<$\emph{id}, \emph{PC}$>$, where \emph{id} defines a class of users (e.g., policeman), and \emph{PC} is a set of \emph{Policy Conditions} on the subject, as defined in Definition \ref{def:policy_cond}. For instance, $<$\emph{user},\{(role $=$ "jailer")\}$>$ refers to a person with the role of jailer.

    \item Object \textit{obj} defines any data whose access is governed by the policy. It is of the form $<$\emph{type}, \emph{PC}$>$, where: \emph{type} defines the type of object, such as a file (e.g., a video, text file, image, etc.), a SQL or noSQL database, a table, a column, a row, or a cell of a table, and \emph{PC} is a set of \emph{Policy Conditions} defined on the object's attributes. For instance, $<$\emph{dataset},\{(region $=$ CT)\}$>$ refers to a dataset whose region is Connecticut.

    \item Action \textit{action} defines any operations that can be performed within a big data environment, from traditional atomic operations on databases (e.g, CRUD operations varying depending on the data model) to coarser operations, such as an Apache Spark Direct Acyclic Graph (DAG), an Hadoop MapReduce, an analytics function call, or an analytics pipeline.

    \item Environment \textit{env} defines a set of conditions on contextual attributes, such as time of the day, location, IP address, risk level, weather condition, holiday/workday, emergency. It is a set \emph{PC} of \emph{Policy Conditions} as defined in Definition \ref{def:policy_cond}. For instance, $<$\emph{env},\{(time $=$ "night")\}$>$ refers to a policy that is applicable only at night.

    \item Data Transformation \textit{\TP} defines a set of security and privacy-aware transformations on \textit{obj}, focusing on data protection, as well as compliance to regulations and standards, in addition to simple format conversions.
  \end{description}
\end{definition}
Policy are evaluated twice, and activated once. The first evaluation is performed when a service applies for a node \vi{i}$\in$\V$_S$, and the second evaluation is performed when the service requests access to data.
The activation consists in the execution of the data transformation function \TP\ triggered right before the service execution in order to deliver protected data to the service.

\subsection{Example}\label{sec:example}
As an example, let us consider a pipeline template G(\V,\E,\myLambda,\myGamma) with three nodes, as depicted in \cref{fig:service_composition_example}.
It includes three key stages in our reference scenario: data anonymization (\vi{1}), data enrichment (\vi{2}), and data aggregation (\vi{3}), each stage with its policy $p$ and functional description \F.

%\begin{enumerate*}[label=n\arabic*)]
%  \item
The first node (\vi{1}) is responsible for data anonymization.
It specifies an anonymization policy ($\myLambda(v_1)$) to protect sensitive information, such as personally identifiable information (PII) in the dataset.
The transformation function \TF{1} in $\myGamma(v_1)$ is an empty function \TF{a}, as no functional transformation is required for anonymization.
%   \item

The second node (\vi{2}) focuses on data enrichment, where additional information from the states of New York and New Hampshire is integrated into the dataset.
It requires a data enrichment policy ($\myLambda(v_2)$) to ensure that the added data is relevant and compliant with privacy regulations.
The transformation function \TF{2} in $\myGamma(v_2$) is an additive function \TF{a}, which merges and integrates the external data with the existing dataset.
  %  \item

  The third node (\vi{3}) is responsible for aggregating data, including statistical measures like averages, medians, and some more statistics.
  It follows an aggregation policy ($\myLambda(v_3)$) to define how the aggregation should be performed, and ensure compliance with privacy and security regulations.
  The transformation function \TF{3} in $\myGamma(v_3)$ is a transformation function \TF{t}, which computes the required statistics and aggregates the data.
  %\end{enumerate*}

  \section{Service Instance}

  \begin{figure}[ht!]
    \centering
    \begin{tikzpicture}[scale=0.85]
      \node[draw, circle] (node1) at (0,0) {$s^\prime_r$};
      \node[draw, circle] (node2) at (1,0) {$s^\prime_1$};
      \node[draw, circle] (node3) at (2,0) {$\timesOperator$};
      \node[draw, circle] (node4) at (3,-1) {$s^\prime_2$};
      \node[draw, circle] (node5) at (3,1) {$s^\prime_3$};
      \node[draw, circle] (node6) at (4,0) {$\timesOperator$};
      \node[draw, circle] (node65) at (5,0) {$s^\prime_4$};
      \node[draw, circle] (node7) at (6,0) {$\plusOperator$};
      \node[draw, circle] (node8) at (7,1) {$s^\prime_5$};
      \node[draw, circle] (node9) at (7,-1) {$s^\prime_6$};
      \node[draw, circle] (node10) at (8,0) {$\plusOperator$};
      \node[draw, circle] (node11) at (9,0) {$s^\prime_7$};
      % Text on top
      \node[above] at (node1.north) { \footnotesize$\instanceChartAnnotation$};
      \node[above] at (node2.north) { \footnotesize$\instanceChartAnnotation$};
      \node[above] at (node3.north) {};
      \node[above] at (node4.north) { \footnotesize$\instanceChartAnnotation$};
      \node[above] at (node5.north) { \footnotesize$\instanceChartAnnotation$};
      \node[above] at (node65.north) { \footnotesize$\instanceChartAnnotation$};
      \node[above] at (node8.north) { \footnotesize$\instanceChartAnnotation$};
      \node[above] at (node9.north) { \footnotesize$\instanceChartAnnotation$};
      \node[above] at (node11.north) { \footnotesize$\instanceChartAnnotation$};
      % Connection
      \draw[->] (node1) -- (node2);
      \draw[->] (node2) -- (node3);
      \draw[->] (node3) -- (node4);
      \draw[->] (node3) -- (node5);
      \draw[->] (node5) -- (node6);
      \draw[->] (node4) -- (node6);
      \draw[->] (node6) -- (node65);
      \draw[->] (node65) -- (node7);
      \draw[->] (node7) -- (node8);
      \draw[->] (node7) -- (node9);
      \draw[->] (node8) -- (node10);
      \draw[->] (node9) -- (node10);
      \draw[->] (node10) -- (node11);
    \end{tikzpicture}
    \caption{Service composition instance}
    \label{fig:service_composition_instance}
  \end{figure}

  \subsection{Instance}
  % \hl{ANCHE QUA COME PER IL TEMPLATE PROVEREI A ESSERE UN POCO PIU' FORMALE. GUARDA IL PAPER CHE TI HO PASSATO.}
  Given the \pipelineTemplate we define our \pipeline instantiation technique as a function that takes as input a \pipelineTemplate \tChartFunction and different sets of candidate services,
  each satisfying the policy requirements of one vertex, and returns as output a \pipelineInstance \iChartFunction.
  In \iChartFunction, every invocations $\vi{i}\in\V$ contains a service instance, and every branching $v\in\Vplus\bigcup\Vtimes$ is maintained as it is. We formally define our \pipelineInstance as follows.

  \begin{definition}[Pipeline Instance]\label{def:instance}
    Let \tChartFunction be a Service Template, a Service Instance $\iChartFunction$ is a directed acyclic graph where:
    \begin{enumerate*}[label=\roman*)]
      \item $s_r=s'_r$,
      \item for each vertex $\vi{}\in\V_{\timesOperator}\cup\V_{\plusOperator}$ it exists a corresponding vertex $\vii{}\in\Vp_{\timesOperator}\cup\Vp_{\plusOperator}$,
      \item for each $\vi{i}\in\V_S$ annotated with policy \P{i} it exists a corresponding \vii{i}$\in$ \Vp$_S$ instantiated with a real service $s_i$
    \end{enumerate*}
    and , such that the following conditions hold:
    \begin{enumerate}[label=\arabic*)]
      \item $s_i$ satisfies policy requirements in \tChartFunction.
      \item $s_i$ satisfies functional requirements  in \tChartFunction.
    \end{enumerate}
  \end{definition}

  Condition 1 is needed to preserve the process functionality, as it simply states that each service $s_i$ must satisfy the functional requirements of the corresponding vertex in the \pipelineTemplate.
  Condition 2 states that each service $s_i$ must satisfy the policy requirements \myLambda(\vi{i}) of the corresponding vertex \vi{i} in the \pipelineTemplate.
  Condizione 1 Ã¨ soddisfatta da tutti

  % Le considerazioni che seguono partono dall'assunto che  T sia uguale a T_p U T_f senza lack of generality

  The \pipelineInstance  is generated by traversing the \pipelineTemplate with a breadth-first search algorithm, starting from the root vertex \vi{r}.
  Then for each vertex \vi{i} in the pipeline template, the corresponding vertex \vii{i}$\in$\Vp\ is generated.
  Finally, for each vertex \vii{i}$\in$\Vp, a two-step selection approach is applied as follows.
  \begin{itemize}

    \item \textit{Filtering Algorithm} -
    \item It matches the policy \myLambda(\vi{i}) against service profile and returns as output a set of services that match the policy.
          Formally, let us consider a set S of candidate services \si, each one annotated with a profile.

          Assuming that policy matching are successful for each \s{i}$\in$S. The matching process is successful if the service profile satisfies \myLambda(\vi{i});
          otherwise, \si is discarded and not considered for selection.
          The matching algorithm  returns a subset $S'\subseteq S$ of compatible services, which represent the possible candidates for selection.

    \item \textit{Comparison Algorithm} - Upon retrieving a set of compatible services, it produces a ranking of these services according to a scoring function.
          More details about the metrics are provided in Section \ref{sec:metrics}.
          Formally, compatible services \si$\in$S' are ranked on the basis of a scoring function.
          The best service \si is then selected and integrated in $\vii{i}\in \Vp$.
          There are many ways of choosing a scoring function, we present those used in this article in Section \ref{sec:metrics}.




  \end{itemize}

  When all vertices $\vi \in V$ have been visited, G' contains a service instance for each \v in \Vp, and the \pipelineInstance is complete.

\begin{example}\label{ex:instance}

  As an example, let us consider the same template G(\V,\E,\myLambda,\myGamma) with three nodes, described in \cref{sec:example}.
  It includes three key stages in our reference scenario: data anonymization (\vi{1}), data enrichment (\vi{2}), and data aggregation (\vi{3}), each stage with its policy $p$.

  The first node (\vi{1}) is responsible for data anonymization.
  In the system there are three services that satisfy the functional requirements of the first node, namely $s_1$, $s_2$ and $s_3$.
  The first service $s_1$ is annotated with a profile that satisfies the policy requirements of the first node, same for the second service $s_2$.
  The third service $s_3$ is annotated with a profile that does not satisfy the policy requirements of the first node.
  The filtering algorithm returns the set $S'=\{s_1,s_2\}$.
  The comparison algorithm is then applied to $S'$ and returns a ranking of the services according to a scoring function, from which results that $s_1$ is the best service.
  The best service $s_1$ is then selected and integrated in $\vii{1}\in \Vp$.
  The same logic is applied to the \vi{2} and \vi{3} and any other node in the pipeline template.
  %\end{enumerate*}

\end{example}


% \begin{figure}[H]
%   \centering

%   \begin{tikzpicture}
%     % Nodes
%     \node[draw, circle, minimum size=0.4cm, draw=gray, text opacity=0.5] (node11) at (0,1.2) {Sx};
%     \node[draw, circle, minimum size=1cm] (node1) at (0,0) {S1};
%     \node[draw, circle, minimum size=0.4cm, draw=gray, text opacity=0.5] (node10) at (0,-1.2) {Sy};

%     \node[draw, circle, minimum size=0.4cm, draw=gray, text opacity=0.5] (node22) at (2,1.2) {Sx};
%     \node[draw, circle, minimum size=1cm] (node2) at (2,0) {S2};
%     \node[draw, circle, minimum size=0.4cm, draw=gray, text opacity=0.5] (node21) at (2,-1.2) {Sy};

%     \node[draw, circle, minimum size=1cm] (node3) at (4,0) {$\timesOperator$};

%     \node[draw, circle, minimum size=0.4cm, draw=gray, text opacity=0.5] (node42) at (5,-1.5) {Sx};
%     \node[draw, circle, minimum size=1cm] (node4) at (6,-1.5) {S3};
%     \node[draw, circle, minimum size=0.4cm, draw=gray, text opacity=0.5] (node41) at (7,-1.5) {Sy};

%     \node[draw, circle, minimum size=1cm] (node5) at (6,1.5) {S4};
%     \node[draw, circle, minimum size=0.4cm, draw=gray, text opacity=0.5] (node51) at (5,1.5) {Sx};
%     \node[draw, circle, minimum size=0.4cm, draw=gray, text opacity=0.5] (node52) at (7,1.5) {Sy};
%     % Connection
%     \draw[->] (node1) -- (node2);
%     \draw[->] (node2) -- (node3);
%     \draw[->] (node3) -- (node4);
%     \draw[->] (node3) -- (node5);
%   \end{tikzpicture}
%   \caption{Service composition instance}
%   \label{fig:service_composition_instance}
% \end{figure}
% \[ \forall S \in \mathrm{S}_{C}  \exists  \iChartFunction(S) = \mathrm{S}_{1} \]


\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{serviceDetail.pdf}
  \caption{Service Detail}
  \label{fig:service_detail}reinstall remote-ssh
\end{figure}
