\documentclass[sn-mathphys-num,referee]{sn-jnl}
\usepackage{natbib} % For citations

%\usepackage{cite}
\usepackage{graphicx}
\usepackage{psfrag}
\usepackage{anyfontsize}
\usepackage{url}
\usepackage{color}
\usepackage{balance}
\usepackage[all]{xy}
\usepackage{xspace}
\usepackage{listings}
\usepackage{adjustbox}
\usepackage{array,booktabs,arydshln,xcolor}
\usepackage{tikz}
\usetikzlibrary{shapes,patterns,calc,shapes.geometric,arrows,positioning,backgrounds}
\usepackage{float}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{url}
\usepackage{amsthm}
\usepackage{float}
\usepackage{amsmath}
\usepackage[capitalise]{cleveref}
\usepackage{soul}
\usepackage[inline]{enumitem}
\usepackage{xcolor}
\usepackage{amssymb}
\usepackage{pifont}
\usepackage{epstopdf}
\usepackage{subcaption}
\graphicspath{{Images/}}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}[section]

\input{macro}

\begin{document}

\title[Balancing Data Quality and Protection in Distributed Big Data Pipelines]{Balancing Data Quality and Protection in Distributed Big Data Pipelines}
\keywords{Access Control, Big Data, Data Transformation, Data Ingestion}

\author[1]{\fnm{Marco} \sur{Anisetti}}\email{marco.anisetti@unimi.it}
\author*[1]{\fnm{Claudio A.} \sur{Ardagna}}\email{claudio.ardagna@unimi.it}
\author[1]{\fnm{Chiara} \sur{Braghin}}\email{chiara.braghin@unimi.it}
\author[1]{\fnm{Ernesto} \sur{Damiani}}\email{ernesto.damiani@unimi.it}
\author[1]{\fnm{Antongiacomo} \sur{Polimeno}}\email{antongiacomo.polimeno@unimi.it}

\affil[1]{\orgdiv{Dipartimento di Informatica}, \orgname{Università degli Studi di Milano}, \orgaddress{\city{Milano}, \country{Italy}}}

\maketitle

\abstract{
  The conflict between the need of protecting and sharing data is hampering the spread of big data applications.
  Proper security and privacy assurance is required to protect data owners, while proper data access and sharing are fundamental to implement smart big data solutions.
  In this context, access control systems assume a central role for balancing the need of data protection and sharing.
  However, given the software and technological complexity of big data ecosystems, existing solutions are not suitable because they are neither general nor scalable, and do not support a dynamic and collaborative environment.
  In this paper, we propose an access control system that enforces access to data in a distributed, multi-party big data environment.
  It is based on data annotations and secure data transformations performed at ingestion time.
  We show the feasibility of our approach with a case study in a smart city domain using an Apache-based big data engine.

  In today's data landscape, the coexistence of data quality and data privacy is critical to support high-value services and pipelines.
  Our approach seeks to harmonize these objectives by establishing a data governance framework that balances privacy and data quality.
}

\tikzset{
  do path picture/.style={%
      path picture={%
          \pgfpointdiff{\pgfpointanchor{path picture bounding box}{south west}}%
          {\pgfpointanchor{path picture bounding box}{north east}}%
          \pgfgetlastxy\x\y%
          \tikzset{x=\x/2,y=\y/2}%
          #1
        }
    },
  cross/.style={do path picture={
          \draw [line cap=round ] (-1,-1) -- (1,1) (-1,1) -- (1,-1);
        }},
  plus/.style={do path picture={
          \draw [line cap=round] (-3/4,0) -- (3/4,0) (0,-3/4) -- (0,3/4);
        }}
}

\input{introduction}
\input{system_model}
\input{pipeline_template.tex}
\input{pipeline_template_example.tex}
\input{pipeline_instance.tex}
\input{pipeline_instance_example.tex}
\input{metrics}
\input{experiment}
\input{related}

\section{Conclusions}\label{sec:conclusions}
In the realm of distributed big data pipelines, managing data while ensuring both quality and protection presents numerous challenges.
This paper introduced a framework specifically designed to address these dual concerns.
Our data governance model employs policies and ongoing monitoring to address data security and privacy challenges, without compromising data integrity.
The key point of the framework is its ability to annotate each element of the pipeline with specific data protection requirements and functional specifications.
This method can enhances compliance with regulatory standards and improves data quality by preserving maximum information during transformation processes.
Experimental results have confirmed the effectiveness of our parametric heuristic in addressing the computationally complex NP-hard service selection problem.
Making use of a realistic dataset, these experiments trying to evaluate the framework’s ability to sustain high data quality while ensuring robust data protection, which is essential for applications where both data utility and privacy must coexist.

To fully understand the impact of dataset selection on the retrieved quality and to ensure heuristic robustness across various scenarios, further investigation is planned for future work.
This research will aim to validate the findings of this paper and explore deeper insights into the applicability of the heuristics across different contexts.


\clearpage
%\bibliographystyle{spbasic}      % basic style, author-year citations
%%%%%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
\bibliography{bib_on_BigDataAccessControl}   % name your BibTeX data base

\end{document}

