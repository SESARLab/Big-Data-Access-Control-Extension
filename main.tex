\documentclass[sn-mathphys-num,referee]{sn-jnl}
\usepackage{natbib} % For citations

%\usepackage{cite}
\usepackage{graphicx}
\usepackage{psfrag}
\usepackage{anyfontsize}
\usepackage{url}
\usepackage{color}
\usepackage{balance}
\usepackage[all]{xy}
\usepackage{xspace}
\usepackage{listings}
\usepackage{adjustbox}
\usepackage{array,booktabs,arydshln,xcolor}
\usepackage{tikz}
\usetikzlibrary{shapes,patterns,calc,shapes.geometric,arrows,positioning,backgrounds}
\usepackage{float}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{url}
\usepackage{amsthm}
\usepackage{float}
\usepackage{amsmath}
\usepackage[capitalise]{cleveref}
\usepackage{soul}
\usepackage[inline]{enumitem}
\usepackage{xcolor}
\usepackage{amssymb}
\usepackage{pifont}
\usepackage{epstopdf}
\usepackage{subcaption}
\graphicspath{{Images/}}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}[section]

\input{macro}

\begin{document}

\title[Balancing Data Quality and Protection in Distributed Big Data Pipelines]{Balancing Data Quality and Protection in Distributed Big Data Pipelines}
\keywords{Access Control, Big Data, Data Transformation, Data Ingestion}

\author[1]{\fnm{Marco} \sur{Anisetti}}\email{marco.anisetti@unimi.it}
\author*[1]{\fnm{Claudio A.} \sur{Ardagna}}\email{claudio.ardagna@unimi.it}
\author[1]{\fnm{Chiara} \sur{Braghin}}\email{chiara.braghin@unimi.it}
\author[1]{\fnm{Ernesto} \sur{Damiani}}\email{ernesto.damiani@unimi.it}
\author[1]{\fnm{Antongiacomo} \sur{Polimeno}}\email{antongiacomo.polimeno@unimi.it}

\affil[1]{\orgdiv{Dipartimento di Informatica}, \orgname{Università degli Studi di Milano}, \orgaddress{\city{Milano}, \country{Italy}}}

\maketitle

\abstract{
  The conflict between the need of protecting and sharing data is hampering the spread of big data applications.
  Proper security and privacy assurance is required to protect data owners, while proper data access and sharing are fundamental to implement smart big data solutions.
  In this context, access control systems assume a central role for balancing the need of data protection and sharing.
  However, given the software and technological complexity of big data ecosystems, existing solutions are not suitable because they are neither general nor scalable, and do not support a dynamic and collaborative environment.
  In this paper, we propose an access control system that enforces access to data in a distributed, multi-party big data environment.
  It is based on data annotations and secure data transformations performed at ingestion time.
  We show the feasibility of our approach with a case study in a smart city domain using an Apache-based big data engine.

  In today's data landscape, the coexistence of data quality and data privacy is critical to support high-value services and pipelines.
  Our approach seeks to harmonize these objectives by establishing a data governance framework that balances privacy and data quality.
  
  Big data’s principle of data maximization and open-ended purpose clashes with data protection regulation.

Last, we highlight with four use cases how the principles of big data, specifically data maximization, clash with the principles of EU data protection regulation. Practically, our study provides guidelines for IT and innovation managers how to arrange and govern the sharing of data among multiple organizations.

}

\tikzset{
  do path picture/.style={%
      path picture={%
          \pgfpointdiff{\pgfpointanchor{path picture bounding box}{south west}}%
          {\pgfpointanchor{path picture bounding box}{north east}}%
          \pgfgetlastxy\x\y%
          \tikzset{x=\x/2,y=\y/2}%
          #1
        }
    },
  cross/.style={do path picture={
          \draw [line cap=round ] (-1,-1) -- (1,1) (-1,1) -- (1,-1);
        }},
  plus/.style={do path picture={
          \draw [line cap=round] (-3/4,0) -- (3/4,0) (0,-3/4) -- (0,3/4);
        }}
}

\input{introduction}
\input{system_model}
\input{pipeline_template.tex}
\input{pipeline_template_example.tex}
\input{pipeline_instance.tex}
\input{pipeline_instance_example.tex}
\input{metrics}
\input{experiment}
\input{related}

\section{Conclusions}\label{sec:conclusions}
In the realm of distributed data service pipelines, managing pipelines while ensuring both data quality and data protection presents numerous challenges. This paper proposed a framework specifically designed to address this dual concern. Our data governance model employs policies and continuous monitoring to address data security and privacy challenges, while preserving data quality, in service pipeline generation. The key point of the framework is in its ability to annotate each element of the pipeline with specific data protection requirements and functional specifications, then driving service pipeline construction. This method enhances compliance with regulatory standards and improves data quality by preserving maximum information across pipeline execution. Experimental results confirmed the effectiveness of our sliding window heuristic in addressing the computationally complex NP-hard service selection problem at the basis of service pipeline construction. Making use of a realistic dataset, our experiments evaluated the framework's ability to sustain high data quality while ensuring robust data protection, which is essential for pipelines where both data utility and privacy must coexist. To fully understand the impact of dataset selection on the retrieved quality and to ensure heuristic robustness across various scenarios, further investigation is planned for our future work. Future work will then %validate the findings of this paper and
explore deeper insights into the applicability of our heuristics across different scenarios.


\clearpage
%\bibliographystyle{spbasic}      % basic style, author-year citations
%%%%%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
\bibliography{bib_on_BigDataAccessControl}   % name your BibTeX data base

\end{document}

