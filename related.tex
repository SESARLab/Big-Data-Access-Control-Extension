\section{Related Work}\label{sec:related}

Given the breadth of topics covered, the related work is discussed separately to provide a more detailed and organized review. In Section  \ref{sec:dataquality}, we address the issue of the lack of consensus on the definition of data quality and, consequently, on data quality metrics when applying data protection transformations. In Section \ref{sec:datagov}, we examine existing data governance solutions that tackle the problem of data protection when sharing data among different services. In Section \ref{sec:servicesel}, we review the literature on QoS (Quality of Service) service selection.

%%%%%%%%%%%%%%%%%%%%
\subsection{Data protection and data quality}\label{sec:dataquality}
%%%%%%%%%%%%%%%%%%%%

Data quality is a widely studied research topic across various communities and perspectives, such as the database community or when evaluating privacy preserving data mining techniques. In the context of big data, data quality primarily refers to the extent to which big data meets the requirements and expectations of its intended use, encompassing various dimensions and characteristics to ensure the data is reliable, accurate, and valuable for analysis and decision-making. Specifically, accuracy denotes the correctness of the data, ensuring it accurately represents the real-world entities and events it models.

With the increasing need to protect sensitive data, the notion of data quality has expanded to include a broader concept of accuracy, particularly in terms of the proximity of a sanitized value to the original value. 
This shift has emphasized the necessity of metrics to assess the quality of data resulting from anonymization processes. Various data quality metrics have been proposed in existing literature, including generalized information loss (\textit{GenILoss}), discernability metric, minimal distortions, and average equivalence class size ($C_{AVG}$), which may either have broad applicability or be tailored to specific data scenarios \cite{Majeed2021AnonymizationTF,bookMetrics,reviewMetrics}. However, there is currently no metric that is widely accepted by the research community. The main challenge with data quality is its relative nature: its evaluation typically depends on the context in which the data is used and often involves both objective and subjective parameters \cite{dataAccuracy,dataQuality}.
%
A common consideration across all contexts is that accuracy is closely related to the information loss resulting from the anonymization strategy: the lower the information loss, the higher the data quality. In our scenario, we have opted for two generic metrics rooted in data loss assessment - one quantitative and one qualitative. Nonetheless, our framework and heuristic are designed to be modular and flexible, accommodating the chosen metric.

%%
Another critical consideration is the integration of data quality throughout the entire data lifecycle. Historically, the focus within the database management research community has predominantly been on enhancing the quality of source data, neglecting to ensure data quality across the whole processing pipeline, or the resulting outcomes. In \cite{BigDataQaulitySurvey}, %a survey on big data quality is proposed mentioning the well known categories of big data quality grouped by intrinsic, contextual representational and accessibility categories.
the authors propose a holistic quality management model that briefly considers data quality during processing, primarily in the context of prerequisites for preprocessing tasks (e.g., data refinement and enhancement through cleaning processes). In contrast, our approach diverges from this notion of assessing data quality solely during preprocessing, instead advocating for its evaluation at each stage of the big data pipeline. We build upon the evaluation conducted in \cite{impetusPaper} within a specific case study, wherein data protection transformations were implemented at each stage, albeit with only one candidate service.

%%%%%%%%%%%%%%%%%%
\subsection{Data protection and data governance}\label{sec:datagov}
%%%%%%%%%%%%%%%%%%

 


%%%%%%%%%%%%%%%%%%%
\subsection{Service Selection based on data quality}\label{sec:servicesel}
%%%%%%%%%%%%%%%%%%%

